<!DOCTYPE html>
<html lang="en-us">
<title>Data Structures | Software</title>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.104.2" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="/css/index.css">
<link rel="canonical" href="/posts/data-structures/">
<link rel="alternate" type="application/rss+xml" href="" title="Software">

<header>
  
    <a href="/" class="title">Software</a>
  
  
</header>

<article>
  <header>
    <h1>Data Structures</h1>
    <time datetime="2017-05-20T18:53:13&#43;08:00">May 20, 2017</time>
  </header>
  <h1 id="時間複雜度-on-big-o-notation">時間複雜度 O(n), Big O notation</h1>
<p>用來比較不同演算法花多少時間的方法</p>
<h3 id="變因">變因</h3>
<ul>
<li>除法比加法慢一點</li>
<li>記憶體存取區塊不同也有差異</li>
<li>測試規模大的時候能測的比較準確</li>
<li>操作次數的量級重要於精確的值</li>
</ul>
<h3 id="計算">計算</h3>
<ul>
<li>假設所有操作都是一樣的時間 (加減乘除/取餘數/存取記憶體/判斷運算子)</li>
<li>假設演算法 3n^2 + 2n + 7, 電腦每秒執行 100萬次, n=2000, 需要 12,004,007 次的加法操作才能解決此問題, 此電腦需要 12 秒才能跑完</li>
<li>一般電腦是 2,000~8,000萬次/秒</li>
<li>Big-O : O(f(n))</li>
<li>Little-o : o(f(n))</li>
<li>n 是輸入的規模</li>
</ul>
<h3 id="常見的幾種時間複雜度與演算法">常見的幾種時間複雜度與演算法</h3>
<p>O(n!) &gt; O(2^n) &gt; O(n^2) &gt; O(nlogn) &gt; O(n) &gt; O(logn) &gt; O(1)</p>
<ul>
<li>O(1) constant
<ul>
<li>陣列讀取 (已經知道要從陣列取出哪一個 index)</li>
</ul>
</li>
<li>O(logn) logarithmic
<ul>
<li>base is 2</li>
<li>an array storing 1M items, will do 19 comparison with binary search</li>
<li>二分搜尋 (從小到大的排列裡面每次搜尋都取中間值)</li>
</ul>
</li>
<li>O(n) linear
<ul>
<li>簡易搜尋 (搜尋時從頭跑到尾)</li>
<li>for loop</li>
<li>an array storing 1 to 10, linear search</li>
<li>String[] copy = new String[names.length]</li>
</ul>
</li>
<li>O(nlogn) log linear
<ul>
<li>合併排序 (把大陣列一直重覆切一半成小陣列, 直到所有小陣列都只有一個元素, 再重覆將兩個小陣列合併成一個陣列, 直到所有陣列都合併成一個大陣列) <a href="https://commons.wikimedia.org/wiki/File:Merge-sort-example-300px.gif">gif demonstration</a></li>
</ul>
</li>
<li>O(n^2) quadratic
<ul>
<li>double for loop</li>
<li>選擇排序 (從未排序的數字中找出最小值, 再丟到最左邊)</li>
<li>插入排序 (從未排序的數字讀出一個數, 根據大小把它往前插入到適當的位置) <a href="https://commons.wikimedia.org/wiki/File:Insertion-sort-example.gif">gif demonstration</a></li>
</ul>
</li>
<li>O(2^n) exponential
<ul>
<li>recursive 費波那契數列 (Fibonacci numbers) (是指在一串數字中每一項是前兩項的和 e.g. <code>0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55</code>, 當 n 不是 0 或 1 時, <code>fibo(n) = fibo(n-1) + fibo(n-2)</code>)</li>
</ul>
</li>
<li>O(n!) factorial</li>
</ul>
<h3 id="common-data-structures">Common Data Structures</h3>
<ul>
<li>arrays
<ul>
<li>Time
<ul>
<li>Access O(1)
<ul>
<li>Arrays have O(1) access time because elements are stored in a contiguous block of memory and the memory location of an element can be calculated based on its index, making it possible to access an element quickly in constant time.</li>
</ul>
</li>
<li>Search O(n)
<ul>
<li>Arrays have O(n) search time because finding a specific element typically requires checking each element one by one, and the time required to find an element is proportional to the number of elements in the array.</li>
</ul>
</li>
<li>Insertion/Deletion O(n)
<ul>
<li>Arrays have O(n) insertion and deletion time because, in general, inserting or deleting an element in the middle of an array requires shifting all the elements after the insertion or deletion point, which takes linear time proportional to the number of elements in the array.</li>
<li>For example, inserting or deleting the first item requires shifting all elements one position to the right or left.</li>
</ul>
</li>
</ul>
</li>
<li>Space O(n)
<ul>
<li>The total amount of memory required to store the array is n * m bits. As the number of elements in the array grows, the amount of memory required also grows linearly, making the space complexity O(n).</li>
<li>Note that the space complexity of an array does not depend on the size of the elements, only on the number of elements.</li>
</ul>
</li>
<li>unordered data</li>
</ul>
</li>
<li>stacks
<ul>
<li>Time
<ul>
<li>Access/Search O(n)
<ul>
<li>Stacks take O(n) access time because, in general, accessing an element in a stack requires starting at the top of the stack and then following the chain of pointers to the desired element, which takes linear time proportional to the number of elements in the stack.</li>
<li>Stacks take O(n) search time because finding an element in a stack typically requires starting at the top of the stack and following the chain of pointers until the desired element is found, which takes linear time proportional to the number of elements in the stack.</li>
</ul>
</li>
<li>Insertion/Deletion O(1)
<ul>
<li>Stacks take O(1) insertion and deletion time because they follow the Last-In-First-Out (LIFO) principle, where the most recently added element is always the first to be removed. In a stack, inserting (push) or deleting (pop) an element only requires updating the top pointer, which takes constant time and does not depend on the size of the stack.</li>
</ul>
</li>
</ul>
</li>
<li>Space O(n)
<ul>
<li>Stacks take O(n) space complexity because each element in a stack requires a constant amount of memory to store, and the amount of memory required by a stack is proportional to the number of elements stored in the stack.</li>
</ul>
</li>
<li>LIFO</li>
</ul>
</li>
<li>queues
<ul>
<li>Time
<ul>
<li>Access/Search O(n)
<ul>
<li>Queues take O(n) access and search time because, in general, accessing or searching for an element in a queue requires starting at one end of the queue and then following the chain of pointers until the desired element is found, which takes linear time proportional to the number of elements in the queue.</li>
</ul>
</li>
<li>Insertion/Deletion O(1)
<ul>
<li>Queues take O(n) insertion and deletion time because they follow the First-In-First-Out (FIFO) principle, where the first element added to the queue is the first to be removed. In a queue, inserting (enqueue) an element at the end of the queue and deleting (dequeue) an element from the front of the queue both require updating the front and rear pointers, which takes linear time proportional to the number of elements in the queue.</li>
</ul>
</li>
</ul>
</li>
<li>Space O(n)</li>
<li>FIFO</li>
</ul>
</li>
<li>linked list
<ul>
<li>Time
<ul>
<li>Access/Search O(n)
<ul>
<li>Linked lists take O(n) access and search time because, in general, accessing or searching for an element in a linked list requires following the chain of pointers from one element to the next until the desired element is found, which takes linear time proportional to the number of elements in the linked list.</li>
</ul>
</li>
<li>Insertion/Deletion O(1)
<ul>
<li>Linked lists take O(1) insertion and deletion time because each element in a linked list is connected to its neighbors via pointers, making it possible to insert or delete an element by simply updating the pointers of the neighboring elements.</li>
</ul>
</li>
</ul>
</li>
<li>Space O(n)</li>
<li>no fixed size</li>
<li>takes up space (needs to store point and metadata)</li>
<li>slow lookup (walk through each item)</li>
<li>unordered data</li>
</ul>
</li>
<li>hash tables
<ul>
<li>Time
<ul>
<li>Access N/A</li>
<li>(avg) Search/Insertion/Deletion O(1)
<ul>
<li>Hash tables can get an average time complexity of O(1) because they use a hash function to map keys to indices in an array, which allows for fast access to elements. When the hash function is well-designed and the hash table is properly balanced, each key maps to a unique index, and accessing an element in the hash table can be done in constant time.</li>
</ul>
</li>
<li>(worse) Search/Insertion/Deletion O(n)
<ul>
<li>Hash tables use a hash function to map keys to indices in an array, which allows for fast search for elements. However, if the hash function is poorly designed or the hash table becomes too full, collisions can occur, where multiple keys map to the same index.</li>
<li>In the worst case scenario, when all keys collide and map to the same index, the hash table becomes a linked list, and insertion becomes an O(n) operation because you have to traverse the linked list to find the right place to insert the new element.</li>
</ul>
</li>
</ul>
</li>
<li>Space O(n)</li>
</ul>
</li>
<li>trees
<ul>
<li>Binary Search Tree
<ul>
<li>Time
<ul>
<li>(avg) Access/Search/Insertion/Deletion O(log(n))
<ul>
<li>binary search trees are structured such that elements are organized in a way that allows for efficient searching, insertion, and deletion operations. When the tree is balanced, the height of the tree is logarithmic with respect to the number of elements in the tree, which results in an average time complexity of O(log n) for these operations.</li>
</ul>
</li>
<li>(worse) Access/Search/Insertion/Deletion O(n)
<ul>
<li>if the tree becomes unbalanced, the height of the tree can be proportional to the number of elements in the tree, resulting in a worst-case time complexity of O(n)</li>
</ul>
</li>
<li>Since the height of a well-balanced BST is O(log(n)), insertion takes O(log(n)) time on average. In the worst case, when the BST is not balanced and becomes a linear chain, the time complexity is O(n)</li>
</ul>
</li>
<li>Space O(n)</li>
<li>pros
<ul>
<li>better than O(n)</li>
<li>ordered</li>
<li>flexible size</li>
</ul>
</li>
<li>cons
<ul>
<li>No O(1) operations</li>
</ul>
</li>
</ul>
</li>
<li>Binary heap
<ul>
<li>pros
<ul>
<li>better than O(n)</li>
<li>priority</li>
<li>flexible size</li>
<li>fast insert</li>
</ul>
</li>
<li>cons
<ul>
<li>slow lookup</li>
</ul>
</li>
</ul>
</li>
<li>tries
<ul>
<li>Suffix Tree</li>
</ul>
</li>
<li>graphs</li>
</ul>
</li>
</ul>
<h3 id="demonstrate-time-complexity-using-code">Demonstrate time complexity using code</h3>
<p>O(1) or constant time</p>
<pre><code>function printFirstItem($arrayOfItems)
{
    print $arrayOfItems[0] . &quot;\n&quot;;
}
</code></pre>
<blockquote>
<p>不論 array 數量是 1 還是 1000, 這個 function 都只需要一步就完成</p>
</blockquote>
<p>O(n) or linear time</p>
<pre><code>function printAllItems($arrayOfItems)
{
    foreach ($arrayOfItems as $item) {
        print $item . &quot;\n&quot;;
    }
}
</code></pre>
<blockquote>
<p>n 指的是 array 的數量, 有幾個就會有幾個動作</p>
</blockquote>
<p>log(n)</p>
<pre><code>function sayHiNTimes($n)
{
    for ($i = 0; $i &lt; $n; $i++) {
        print &quot;hi\n&quot;;
    }
}
</code></pre>
<p>log(2n) = log(n)</p>
<pre><code>function printAllItemsTwice($theArray)
{
    foreach ($theArray as $item) {
        print $item . &quot;\n&quot;;
    }

    // once more, with feeling
    foreach ($theArray as $item) {
        print $item . &quot;\n&quot;;
    }
}
</code></pre>
<p>log(1+n/2+1000) = log(n)</p>
<pre><code>function printFirstItemThenFirstHalfThenSayHi100Times($theArray)
{
    print $theArray[0] . &quot;\n&quot;;

    $middleIndex = floor(count($theArray) / 2);
    $index = 0;

    while ($index &lt; $middleIndex) {
        print $theArray[$index] . &quot;\n&quot;;
        $index++;
    }

    for ($i = 0; $i &lt; 100; $i++) {
        print &quot;hi\n&quot;;
    }
}
</code></pre>
<blockquote>
<p>如果 n 是很大的數, <code>+1000</code> 或 <code>除2</code> 會造成的影響沒有這麼大, 我們可以直接忽略</p>
</blockquote>
<p>O(n^2) or quadratic time</p>
<pre><code>function printAllPossibleOrderedPairs($arrayOfItems)
{
    foreach ($arrayOfItems as $firstItem) {
        foreach ($arrayOfItems as $secondItem) {
            print &quot;$firstItem, $secondItem\n&quot;;
        }
    }
}
</code></pre>
<blockquote>
<p>n 指的是 array 的數量, 此 function 會做 n^2 個動作</p>
</blockquote>
<p>O(n+n2) = O(n^2)</p>
<pre><code>function printAllNumbersThenAllPairSums($arrayOfNumbers)
{
    print &quot;these are the numbers\n&quot;;
    foreach ($arrayOfNumbers as $number) {
        print $number . &quot;\n&quot;;
    }

    print &quot;and these are their sums:\n&quot;;
    foreach ($arrayOfNumbers as $firstNumber) {
        foreach ($arrayOfNumbers as $secondNumber) {
            print $firstNumber + $secondNumber . &quot;\n&quot;;
        }
    }
}
</code></pre>
<p>其他</p>
<ul>
<li>3n^3 + 5n^2 + 10n + 3 = O(n^3)</li>
<li>1000 = O(1)</li>
<li>3n^2+n+20 = O(n^2)</li>
<li>100n = O(n)</li>
<li>n^100 = O(n^100)</li>
<li>2^n = O(2^n)</li>
<li>n^2 = O(n^2)</li>
<li>10nlog n = O(nlog n)</li>
<li>100^n = O(100^n)</li>
<li>n! = O(n!)</li>
<li>30*2^n = O(2^n)</li>
<li>100n = O(n)</li>
</ul>
<h3 id="demonstrate-space-complexity-using-code">Demonstrate space complexity using code</h3>
<p>O(1) space</p>
<pre><code>function sayHiNTimes($n)
{
    for ($i = 0; $i &lt; $n; $i++) {
        print &quot;hi\n&quot;;
    }
}
</code></pre>
<p>O(n) space</p>
<pre><code>function arrayOfHiNTimes($n)
{
    $hiArray = [];
    for ($i = 0; $i &lt; $n; $i++) {
        $hiArray[$i] = 'hi';
    }
    return $hiArray;
}
</code></pre>
<p>其他</p>
<ul>
<li>O(logN) - logarithmic</li>
<li>O(NlogN) - loglinear</li>
<li>O(2^N) - exponential time</li>
<li>O(n^2 /2+100n) = O(n^2)</li>
<li>O(n^3+50n^2+10000) = O(n^3)</li>
<li>O((n+30)*(n+5)) = O(n^2)</li>
<li>O(f(n)) + O(g(n)) is O( f(n) + g(n) ) is O( max(f(n),g(n)) )</li>
<li>O(N) + O(Log N)  =  O(N + Log N)  =  O(max(N,Log N)) = O(N)</li>
<li>O(N) + O(N)  =  O(2N)  =  O(N)</li>
</ul>
<h1 id="list-鏈結串列-或串列">List 鏈結串列 (或串列)</h1>
<ul>
<li>基本單元是 Node (data + pointer)</li>
<li>每個 node 只記錄下一個 node 的位置</li>
<li>起點 (head) 指標指向第一個 node, 最後一個 node 的指標指向 NULL</li>
<li>分類: 單向 / 雙向 / 環狀</li>
<li>操作: insert / delete</li>
<li>優點
<ul>
<li>動態宣告記憶體, 避免記憶體浪費(但 dynamic array 也可以)</li>
<li>快速插入和刪除節點, 只需要更改 pointer 的值, O(1) (array 沒辦法除非要搬元素)</li>
<li>A linked list provides a data structure similar to an array, but with the big advantage that inserting an element in the middle of the list is very cheap, compared to doing so in an array, where we need to shift all elements after the current position.</li>
</ul>
</li>
<li>缺點
<ul>
<li>不能隨機存取 (random access), 不像陣列可以指定取第100個元素</li>
</ul>
</li>
<li>搜尋的時間複雜度是 O(n)</li>
<li>insert / delete 知道位置的話, 時間複雜度是 O(1), 否則必須先搜尋</li>
<li>無 index, 不支援二分搜尋法</li>
<li>串列其實是用陣列實作, 散列在記憶體裡</li>
</ul>
<h3 id="單向">單向</h3>
<ul>
<li>insert: O(1)</li>
<li>delete: O(1)</li>
</ul>
<p>Code:</p>
<pre><code>struct Node{
    int     _data;
    Node*   _next;   // 指標
}

int main() {
    Node* head;     // 紀錄起點
}
</code></pre>
<h3 id="雙向-doubly-linked-list">雙向 (doubly linked list)</h3>
<ul>
<li>每個 node 紀錄上一個跟下一個的位置</li>
<li>跟單向比的好處是它可以 start from the end and go backward</li>
</ul>
<h3 id="環狀">環狀</h3>
<ul>
<li>head 指向第一個</li>
<li>end 指向第一個</li>
</ul>
<h3 id="時間複雜度">時間複雜度</h3>
<ul>
<li>random access
<ul>
<li>Array: Yes</li>
<li>Linked List: No</li>
</ul>
</li>
<li>push front
<ul>
<li>Array: <strong>先把其他的元素往後退一格</strong>, 再插入要的元素到第一格, O(n)</li>
<li>Linked List: 只需要修改 pointer, O(1)</li>
</ul>
</li>
<li>push back
<ul>
<li>Array: 只需要把元素放到最尾端, O(1)</li>
<li>Linked List: 只需要修改 pointer, O(1)</li>
</ul>
</li>
<li>pop front
<ul>
<li>Array: O(n)</li>
<li>Linked List: O(1)</li>
</ul>
</li>
<li>pop back
<ul>
<li>Array: O(1)</li>
<li>Linked List: O(1)</li>
</ul>
</li>
</ul>
<h1 id="binary-search-tree">Binary search tree</h1>
<h3 id="basics">basics</h3>
<p>All child nodes in the tree to the right of root node must be greater than the current node</p>
<p>example:</p>
<pre><code>               101
        33             105
     9     37      104     144
</code></pre>
<p>key points</p>
<ul>
<li>If the BST is balanced, the average time complexity is O(log(n)). However, the worse case (unbalance BST) would be O(n)</li>
<li>Pros
<ul>
<li>better than O(n)</li>
<li>ordered</li>
<li>Flexible size</li>
</ul>
</li>
<li>Cons
<ul>
<li>No O(1) operation</li>
</ul>
</li>
</ul>
<h3 id="the-implementation-difference-between-array-and-linked-list">The implementation difference between Array and Linked List</h3>
<ul>
<li>Array: Need to move several nodes when a node is added or deleted.</li>
<li>Linked List: Improve the drewback of Array.</li>
</ul>
<h1 id="heap">Heap</h1>
<h3 id="basics-1">basics</h3>
<p>A Binary Heap is either Min Heap or Max Heap</p>
<ul>
<li>max-heap: root is the maximum number</li>
<li>min-heap: root is the minimum number</li>
</ul>
<h3 id="use-cases">Use cases</h3>
<ul>
<li>heap sort</li>
<li>priority queue</li>
</ul>
<h3 id="operations">Operations</h3>
<ul>
<li>Insertion
<ul>
<li>Ensure that the tree remains balanced by adding the value to the bottom layer from left to right</li>
<li>Maintain the features of a min/max heap by swapping nodes all the way to the top if needed</li>
</ul>
</li>
<li>Deletion
<ul>
<li>Remove the root node, then replace it with the node from the bottom-rightmost layer of the heap</li>
<li>Maintain the features of a min/max heap by swapping nodes all the way to the bottom if needed</li>
</ul>
</li>
</ul>
<h3 id="the-difference-of-implementation-between-array-and-linked-list">The difference of implementation between array and linked list</h3>
<ul>
<li>array (preferred)
<ul>
<li>pros
<ul>
<li>Easy implementation
<ul>
<li>easy to compute the array index of a node&rsquo;s children</li>
<li>more efficient to find the Kth element of an array than the Kth element of a linked list</li>
</ul>
</li>
<li>Good for time complexity
<ul>
<li>efficient operations such as inserting a new element, deleting the minimum (or maximum) element, and finding the minimum (or maximum) element, which can be done in O(log n) time.</li>
</ul>
</li>
<li>in-place algorithm</li>
</ul>
</li>
<li>cons
<ul>
<li>Memory reallocation: if the heap grows beyond its initial size, it must be resized, leading to wasted space and increased memory usage</li>
</ul>
</li>
</ul>
</li>
<li>linked list
<ul>
<li>pros
<ul>
<li>Dynamic memory allocation: using pointers its easier to grow the data structure size dynamically, you can insert new elements without worrying about reallocating memory</li>
</ul>
</li>
<li>cons
<ul>
<li>Difficult implementation (compared to array)</li>
<li>Bad for time complexity: finding the minimum (or maximum) element, inserting a new element, and deleting the minimum (or maximum) element all have a time complexity of O(n) in the worst case because it may require traversing the entire list to find a specific element</li>
<li>O(n) space</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>How do I make decision which implementation to use, arrays or linked lists?</p>
<ul>
<li>If the array size changes frequently and array is huge
<ul>
<li>yes -&gt; linked list</li>
<li>no -&gt; array</li>
</ul>
</li>
<li>If the performance of operations such as insertion, deletion matters
<ul>
<li>yes -&gt; array</li>
<li>no -&gt; linked list</li>
</ul>
</li>
<li>If memory is significantly limited
<ul>
<li>yes -&gt; array</li>
<li>no -&gt; linked list</li>
</ul>
</li>
</ul>
<h3 id="convert-to-heap-from-binary-tree">Convert to heap from binary tree</h3>
<p>Basically, put bigger value upwards and make it follow the heap&rsquo;s rule.</p>
<p>two ways to implement:</p>
<ul>
<li>from bottom to top</li>
<li>from top to bottom</li>
</ul>
<h1 id="graph">Graph</h1>
<h3 id="basics-2">basics</h3>
<p>Components</p>
<ul>
<li>vertex (node)</li>
<li>edge (arc)</li>
</ul>
<p>Types</p>
<ul>
<li>directed graph
<ul>
<li>u -&gt; v</li>
<li>(u, v)</li>
</ul>
</li>
<li>un-directed graph
<ul>
<li>u &ndash; v</li>
<li>(u, v) and (v, u) are same</li>
</ul>
</li>
</ul>
<h3 id="implementation-using-edge-list">Implementation using Edge list</h3>
<p>graph using array</p>
<pre><code>        2 ---------- 0
      /   \
     1-----3
</code></pre>
<p>represent in code</p>
<pre><code>graph = [[0,2], [2,3], [2,1], [1,3]]
</code></pre>
<blockquote>
<p>Each array element represents a connection between two nodes in the graph</p>
</blockquote>
<h3 id="implementation-using-adjacent-list">Implementation using Adjacent list</h3>
<p>graph</p>
<pre><code>        2 ---------- 0
      /   \
     1-----3
</code></pre>
<p>represent in code using array of linked list</p>
<pre><code>graph = [[2], [2,3], [0,1,3], [1,2]]
</code></pre>
<blockquote>
<ul>
<li>Each array element&rsquo;s index represents a node in the graph, and the values within that element represent connections to that node.</li>
<li>For instance, the index 0 <code>[2]</code> represents a connection between nodes 0 and 2, while the index 1 <code>[2,3]</code> indicates connections between nodes 1 and 2, as well as node 1 and 3.</li>
</ul>
</blockquote>
<p>pros</p>
<ul>
<li>Space Efficient
<ul>
<li>only store the nodes that actually exists in the graph</li>
<li>This works nicely in all kinds of graphs, either dense or sparse, since the maximum space usage is always smaller than N^2</li>
</ul>
</li>
<li>Dynamic Allocation
<ul>
<li>allows for dynamic allocation of memory, making it easier to add or remove vertices and edges from the graph</li>
</ul>
</li>
<li>fast to iterate all edges
<ul>
<li>Iterating over all edges in an adjacency list representation is easier and faster compared to an adjacency matrix representation, especially for sparse graphs</li>
</ul>
</li>
</ul>
<p>cons</p>
<ul>
<li>Slow to accessing a specific edge / slow to determine if 2 nodes are connected
<ul>
<li>need to list all the nodes that the node is connected to</li>
<li>O(N)</li>
</ul>
</li>
</ul>
<p>use cases</p>
<ul>
<li>Adjacency list is much more efficient for the storage of the graph, especially sparse graphs, when there is a lot less edges than nodes.</li>
<li>suitable for sparse graph</li>
</ul>
<h3 id="implementation-using-adjacent-matrix">Implementation using Adjacent matrix</h3>
<p>graph</p>
<pre><code>        2 ---------- 0
      /   \
     1-----3
</code></pre>
<p>represent in code using array</p>
<pre><code>graph = {
    [0,0,1,0],
    [0,0,1,1],
    [1,1,0,1],
    [0,1,1,0]
}
</code></pre>
<blockquote>
<ul>
<li>It has a similar concept to adjacent list.</li>
<li>The index 0 in the 2-dimensional array represents node 0 in the graph, and the presence of a value 1 at a particular index within that array element signifies a connection between node 0 and the node represented by that index.</li>
<li>For example, the index 0 <code>[0,0,1,0]</code> represents a connection between node 0 and node 2, while the index 2 <code>[1,1,0,1]</code> indicates connections betwwen node 2 and node 0, node 2 and node 1, as well as node 2 and node 3.</li>
</ul>
</blockquote>
<p>pros</p>
<ul>
<li>easy to implement</li>
<li>Accessing and updating information about an edge take O(1) time
<ul>
<li>determine if two vertices are adjacent to each other</li>
<li>add an edge in the graph</li>
<li>delete an edge form the graph</li>
</ul>
</li>
</ul>
<p>cons</p>
<ul>
<li>consume more memory O(V^2)
<ul>
<li>if there is a graph with 1000 vertices and 1 edge, in order to store on edge it takes an array of size 1000^2 in memory</li>
<li>not good for a spare graph</li>
</ul>
</li>
<li>Traversing the graph using algorithms like DPS/BFS requires O(V^2) time
<ul>
<li>very slow for algorithms that require iterating over all edges, as the number of edges is proportional to n^2.</li>
</ul>
</li>
</ul>
<p>use cases</p>
<ul>
<li>If the graph contains edges in order of V2, then it is better to use adjacency matrix as compared to adjacency list. This is because the size of both adjacency list and adjacency matrix will be comparable so using adjacecny matrix doesn’t necceessary waste a lot of memeory.</li>
<li>If we want to perform operations like add/delete or check that the vertices are adjancent or not very frequently, then it is recommended to use adjacency matrix since we can perform these operations in constant time.</li>
<li>suitable for dense graph</li>
</ul>
<h1 id="trie">Trie</h1>
<h3 id="basics-3">basics</h3>
<ul>
<li>a tree-like data strucutre</li>
<li>can have more than 2 children</li>
<li>used for search string (like search engine)</li>
</ul>
<h3 id="represent-a-trie-using-linked-list">Represent a trie using linked list</h3>
<p>linked list attributes</p>
<ul>
<li>map[string]*node
<ul>
<li>string is a character</li>
</ul>
</li>
<li>isWord (boolean)</li>
</ul>
<p>trie: <code>[&quot;cat&quot;, &quot;tr&quot;, &quot;trid&quot;, &quot;trie&quot;, &quot;trief&quot;]</code></p>
<pre><code>      [   &quot;c&quot;      &quot;t&quot;    ]
        (false)   (false)
         /            \
      [&quot;a&quot;]          [&quot;r&quot;]
     (false)         (true)
      /                  \
   [&quot;t&quot;]                [&quot;i&quot;]
  (true)               (false)
                            \
                      [  &quot;d&quot;    &quot;e&quot;  ]
                       (true)  (true)
                                   \
                                  [&quot;f&quot;]
                                  (true)
</code></pre>
<h3 id="ref">ref</h3>
<ul>
<li><a href="https://www.youtube.com/watch?v=_r7cfVrn28c">https://www.youtube.com/watch?v=_r7cfVrn28c</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/binary-search-tree-bst-search-insert-remove">https://www.digitalocean.com/community/tutorials/binary-search-tree-bst-search-insert-remove</a></li>
<li>Delete a node in BST <a href="https://www.youtube.com/watch?v=DkOswl0k7s4">https://www.youtube.com/watch?v=DkOswl0k7s4</a></li>
<li>Delete a node in BST <a href="https://www.educative.io/answers/how-to-delete-a-node-from-a-binary-search-tree">https://www.educative.io/answers/how-to-delete-a-node-from-a-binary-search-tree</a></li>
<li>Delete a node in BST <a href="https://www.techiedelight.com/deletion-from-bst/">https://www.techiedelight.com/deletion-from-bst/</a></li>
<li>graph <a href="https://slaystudy.com/advantages-and-disadvantages-of-adjacency-matrix-graph-representation/">https://slaystudy.com/advantages-and-disadvantages-of-adjacency-matrix-graph-representation/</a></li>
<li>graph <a href="https://www.quora.com/What-are-the-pros-and-cons-of-representing-a-graph-in-an-adjacency-list-an-adjacency-matrix-and-objects-classes">https://www.quora.com/What-are-the-pros-and-cons-of-representing-a-graph-in-an-adjacency-list-an-adjacency-matrix-and-objects-classes</a></li>
<li>how graph shows directed graph using adjacency list and matrix <a href="https://www.softwaretestinghelp.com/graph-implementation-cpp/">https://www.softwaretestinghelp.com/graph-implementation-cpp/</a></li>
</ul>

</article>



</html>
