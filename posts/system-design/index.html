<!DOCTYPE html>
<html lang="en-us">
<title>System Design | Software engineering notes</title>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.104.2" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="/css/index.css">
<link rel="canonical" href="/posts/system-design/">
<link rel="alternate" type="application/rss+xml" href="" title="Software engineering notes">

<header>
  
    <a href="/" class="title">Software engineering notes</a>
  
  
</header>

<article>
  <header>
    <h1>System Design</h1>
    
  </header>
  <h1 id="how-can-you-generate-a-key-that-is-guaranteed-to-be-unique">How can you generate a key that is guaranteed to be unique?</h1>
<h3 id="the-possibility-to-get-duplicates-by-uuidv4">The possibility to get duplicates by UUIDv4</h3>
<p>UUIDv4 generates a random id using random numbers, with 122 random bits. The chances of generating a duplicate are extremely low but not zero.</p>
<p>To understand the probability, consider that the number of version 4 UUIDs which can be generated is <code>2^122</code> or about <code>5.3x10^36</code>.</p>
<blockquote>
<p>To put these numbers into perspective, the annual risk of a given person being hit by a meteorite is estimated to be one chance in 17 billion
, which means the probability is about <code>0.00000000006</code> (6 × 10−11), equivalent to the odds of creating a few tens of trillions of UUIDs in a year and having one duplicate.
In other words, only after generating 1 billion UUIDs every second for approximately 100 years would the probability of creating a single duplicate reach 50%.</p>
</blockquote>
<p>The approaches to improve the collision issue</p>
<ul>
<li>Combination of UUID and Timestamp or System-Specific Identifier
<ul>
<li>e.g. use timestamp as prefix or suffix to the UUID</li>
</ul>
</li>
<li>Use a Version 1 UUID (UUIDv1)
<ul>
<li>e.g. the MAC address of the host that generated the UUID and the current time</li>
<li>e.g. privacy concerns since MAC addresses can be traced back to the machine</li>
</ul>
</li>
<li>Check Before Use
<ul>
<li>check whether it&rsquo;s been used before</li>
</ul>
</li>
</ul>
<h3 id="another-way-to-make-sure-that-the-generated-key-is-unique">Another way to make sure that the generated key is unique</h3>
<ul>
<li>Centralized ID Generation
<ul>
<li>Using a centralized server or database that generates and keeps track of IDs used can guarantee uniqueness.</li>
<li>This could involve using an auto-incrementing field in a database, or a dedicated service that generates unique IDs.</li>
<li>However, this approach might not be suitable for systems that need to generate IDs in a distributed or offline manner.</li>
<li>For example
<ul>
<li>generate all unique keys in advance (6 character long keys might be around 56.8 billion) in a table</li>
<li>once the key is used, then mark it by moving it to a separate table with appropriate locking in place</li>
</ul>
</li>
</ul>
</li>
<li>Distributed Consensus (solution to &ldquo;Centralized ID Generation&rdquo;)
<ul>
<li>In a distributed system where a centralized authority for ID generation isn&rsquo;t feasible, a consensus algorithm like Paxos or Raft could be used to agree on the next ID to use.</li>
<li>This requires more complexity and communication between nodes, but can guarantee uniqueness.</li>
</ul>
</li>
</ul>
<h1 id="database-scaling">Database scaling</h1>
<h3 id="vertical-vs-horizontal">Vertical vs Horizontal</h3>
<p>Vertical: increase the capacity of a single server by adding more powerful hardware resources such as CPU, RAM, and storage</p>
<ul>
<li>Pros
<ul>
<li>Less complexity
<ul>
<li>simpler to scale up by adding more resources to a single server</li>
<li>no additional work to maintain data across machines like horizontal scaling does</li>
</ul>
</li>
<li>Data Consistency</li>
</ul>
</li>
<li>Cons
<ul>
<li>Limited Growth
<ul>
<li>There are physical limits to how much you can scale a single server. Once those limits are reached, you&rsquo;ll need to look at horizontal scaling or other options.</li>
</ul>
</li>
<li>Single point of failure</li>
</ul>
</li>
<li>In between
<ul>
<li>Cost
<ul>
<li>Low-cost initially; less cost-effective over time</li>
<li>High-end hardware can also be expensive</li>
</ul>
</li>
<li>Downtime
<ul>
<li>You might need a backup server to handle operations while scaling</li>
<li>With some platforms, you can add resources without causing downtime</li>
</ul>
</li>
</ul>
</li>
<li>User cases
<ul>
<li>If you are operating within a limited budget and require a rapid and cost-effective expansion of your infrastructure, vertical scaling is a good option</li>
<li>You don&rsquo;t know how much traffic or users you will get</li>
<li>infrequent upgdade</li>
</ul>
</li>
</ul>
<p>Horizontal: distribute the database load across multiple servers by adding more instances to the existing pool of servers</p>
<ul>
<li>pros
<ul>
<li>Reliability
<ul>
<li>If one server fails, other servers can take over the load as you are not relying on a single machine</li>
</ul>
</li>
<li>Flexibility
<ul>
<li>based on your usage</li>
</ul>
</li>
<li>Scalability
<ul>
<li>Horizontal scaling allows you to handle larger loads by simply adding more servers</li>
</ul>
</li>
<li>Topographic distribution
<ul>
<li>to server nationwide or global clients</li>
</ul>
</li>
</ul>
</li>
<li>cons
<ul>
<li>More Complexity
<ul>
<li>It requires changes to the application architecture such as implementing sharding or replication strategies</li>
<li>Data partitioning and replication strategies can be complex to implement and maintain. Data integrity and avoiding data duplication can also be challenging</li>
</ul>
</li>
<li>Data inconsistency
<ul>
<li>ensuring data consistency can be challenging due to issues like network partitioning and latency</li>
<li>require more complex coordination and consensus protocols</li>
</ul>
</li>
</ul>
</li>
<li>In between
<ul>
<li>Cost
<ul>
<li>High costs initially; optimal over time</li>
</ul>
</li>
<li>Downtime
<ul>
<li>operation such as addition or removal of nodes doesn&rsquo;t require downtime
<ul>
<li>as it doesn&rsquo;t need to switch the old machine off like vertical scaling does</li>
</ul>
</li>
<li>However, changes such as data sharding, repartitioning, or rebalancing data across nodes can potentially require downtime</li>
</ul>
</li>
<li>Performance
<ul>
<li>The traffic can be shared across connections to multiple machines</li>
<li>However, more servers mean more network traffic and potential for latency as data may need to be synchronized between servers.</li>
</ul>
</li>
</ul>
</li>
<li>Use cases
<ul>
<li>Serve your clients in different geographical locations at lower latency</li>
<li>Expect your service will be in high demand</li>
</ul>
</li>
</ul>
<h3 id="data-consistency">Data consistency</h3>
<ul>
<li>Strong consistency:
<ul>
<li>it requires a synchronisation process between all replica servers before a write operation can be considered complete</li>
<li>Use cases
<ul>
<li>a banking application might require strong consistency to prevent issues like double spending</li>
</ul>
</li>
</ul>
</li>
<li>Eventual Consistency:
<ul>
<li>the write operation might take some time to propagate to all servers</li>
<li>a read operation might return the old data before the write operation propagates to the replica server</li>
<li>Use cases
<ul>
<li>a social media application might be fine with eventual consistency</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>Note that MySQL replication only provides eventual consistency, not strong consistency</p>
</blockquote>
<h3 id="sharding-and-partitioning">Sharding and Partitioning</h3>
<ul>
<li>sharding
<ul>
<li>the data is spread across multiple machines</li>
</ul>
</li>
<li>partitioning
<ul>
<li>break up a large data set into smaller subsets</li>
</ul>
</li>
</ul>
<blockquote>
<p>breaking up large tables into partitions and storing each partition on separate servers is called &ldquo;sharding&rdquo;</p>
</blockquote>
<p>Common methods of database sharding</p>
<ul>
<li>geo-based sharding
<ul>
<li>based on geo the user&rsquo;s location</li>
<li>pros
<ul>
<li>reduce laterncy</li>
</ul>
</li>
<li>cons
<ul>
<li>might not be even distribution of users</li>
</ul>
</li>
</ul>
</li>
<li>Range-based sharding
<ul>
<li>split rows based on a range of values, for example split by the initial of Name (A to I, J to S, T to Z)</li>
<li>pros
<ul>
<li>it is easier to implement</li>
</ul>
</li>
<li>cons
<ul>
<li>can result in the overloading of data on a single physical node</li>
<li>for example shard A might contain a much larger number of rows of data than shard C</li>
</ul>
</li>
</ul>
</li>
<li>Hashed sharding
<ul>
<li>splites rows by assigning the shard key (hash value) to each row of the database</li>
<li>for example 4 rows can be grouped by 2 different hash value</li>
<li>pros
<ul>
<li>more even distribution</li>
</ul>
</li>
<li>cons
<ul>
<li>difficult to assign the hash value when adding more physical shards</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="the-pros-and-cons-of-sharding">The pros and cons of sharding</h3>
<p>pros</p>
<ul>
<li>scalability</li>
<li>smaller data on each shard means better performance</li>
<li>more reliable than a single database</li>
<li>more affordable</li>
</ul>
<p>cons</p>
<ul>
<li>Not all data can be sharded e.g. foreign key relationship can only be maintained in a single shard</li>
<li>manual sharding, each shard runs on seperate servers and cross-shard query such as table join can be difficult to achieve</li>
<li>once sharding is set up, it can be difficult to undo</li>
</ul>
<h3 id="manual-vs-automatic-sharding">Manual vs Automatic sharding</h3>
<h3 id="how-to-read-data-a-shard-server">How to read data a shard server?</h3>
<p>Before sending a query, we need to determine the shard key so that we know which shard we want to query</p>
<p>For example, use the hash function for user_id to get the shard key, then query the appropriate shard based on the shard key</p>
<h3 id="how-to-read-data-across-shard-servers">How to read data across shard servers?</h3>
<p>cross-shard query</p>
<ul>
<li>Not all databases support this operation</li>
<li>like a single, unified dataset, while the actual data may be distributed across multiple nodes</li>
<li>e.g. Google Spanner, CockroachDB</li>
</ul>
<p>There are a few ways to achieve cross-shard query if the database doesn&rsquo;t support</p>
<ul>
<li>Application-Level Joins
<ul>
<li>retrieve the data seperately from each shard and then combine it</li>
</ul>
</li>
<li>Denormalization or Data Duplication
<ul>
<li>make the data that needed to answer a particular query be in a single shard</li>
<li>this might involve duplicating some data across shards</li>
<li>BUT, it increases the complexity</li>
</ul>
</li>
<li>Use a Database that Supports Cross-Shard Queries</li>
</ul>
<h1 id="types-of-bounds">Types of bounds</h1>
<ul>
<li>IO Bound
<ul>
<li>spend most of its time waiting for input/output</li>
<li>e.g. reading from or writing to the file, network communication, DB queries, downloading/uploading</li>
</ul>
</li>
<li>CPU Bound
<ul>
<li>heavily rely on computational power</li>
<li>e.g. mathematical calculations, cryptographic operations, video encoding, image processing, complex algorithms</li>
</ul>
</li>
<li>Memory Bound
<ul>
<li>constrained by available memory</li>
<li>e.g. processing large datasets</li>
<li>can be improved by investigating memory leaks, optimising memory usage</li>
</ul>
</li>
<li>Network Bound
<ul>
<li>limit by network factors</li>
<li>e.g. bandwidth limitations,</li>
<li>e.g. sending or receiving large files, numerous API calls</li>
<li>can be improved by CDN, optimising network config, reducing request,</li>
</ul>
</li>
<li>Disk Bound
<ul>
<li>limited by the data transfer rate of the storage device</li>
<li>increasing CPU or RAM might not help too much</li>
<li>e.g. read/write speed</li>
</ul>
</li>
</ul>
<p>ref:</p>
<ul>
<li><a href="https://en.wikipedia.org/w/index.php?title=Universally_unique_identifier&amp;oldid=755882275#Random_UUID_probability_of_duplicates">Random UUID probability of duplicates</a></li>
<li><a href="https://en.wikipedia.org/wiki/Universally_unique_identifier#Collisions">collisions</a></li>
<li><a href="https://github.com/karanpratapsingh/system-design/blob/main/README.md">https://github.com/karanpratapsingh/system-design/blob/main/README.md</a></li>
<li>chatGPT</li>
<li><a href="https://aws.amazon.com/what-is/database-sharding/">https://aws.amazon.com/what-is/database-sharding/</a></li>
<li><a href="https://docs.oracle.com/en/database/oracle/oracle-database/21/shard/query-processing-multi-shard-queries.html#GUID-E3CF0022-FA38-4DD0-A5D5-7A409EA45F76">https://docs.oracle.com/en/database/oracle/oracle-database/21/shard/query-processing-multi-shard-queries.html#GUID-E3CF0022-FA38-4DD0-A5D5-7A409EA45F76</a></li>
<li><a href="https://www.youtube.com/watch?v=be6PLMKKSto">https://www.youtube.com/watch?v=be6PLMKKSto</a></li>
</ul>

</article>



</html>
