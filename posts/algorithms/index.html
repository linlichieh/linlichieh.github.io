<!DOCTYPE html>
<html lang="en-us">
<title>Algorithms | Software</title>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.104.2" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="/css/index.css">
<link rel="canonical" href="/posts/algorithms/">
<link rel="alternate" type="application/rss+xml" href="" title="Software">

<header>
  
    <a href="/" class="title">Software</a>
  
  
</header>

<article>
  <header>
    <h1>Algorithms</h1>
    <time datetime="2017-05-20T18:56:16&#43;08:00">May 20, 2017</time>
  </header>
  <h1 id="sorting-algorithm">Sorting algorithm</h1>
<p>Comparison</p>
<ul>
<li>Bubble Sort
<ul>
<li>Time O(n^2)
<ul>
<li>bubble sort works by repeatedly swapping adjacent elements if they are in the wrong order, and it continues this process until the array is sorted. The number of swaps required to sort the array is proportional to the square of the number of elements in the array</li>
</ul>
</li>
<li>Space O(1)</li>
</ul>
</li>
<li>Insertion Sort
<ul>
<li>Time O(n^2)
<ul>
<li>insertion sort works by iterating over the elements in the array, and for each element, it shifts all the elements that are greater than it to the right in order to make room for it in its final position. The number of shifts required to insert each element is proportional to the number of elements that have already been processed</li>
</ul>
</li>
<li>Space O(1)</li>
</ul>
</li>
<li>Selection Sort
<ul>
<li>Time O(n^2)
<ul>
<li>selection sort works by repeatedly finding the minimum element in the unsorted portion of the array and swapping it with the first unsorted element. The number of swaps required to sort the array is proportional to the square of the number of elements in the array</li>
</ul>
</li>
<li>Space O(1)</li>
</ul>
</li>
<li>Merge Sort
<ul>
<li>Time O(n log(n))
<ul>
<li>merge sort works by dividing the array into two halves, sorting each half separately, and then merging the two sorted halves back together. The merging process takes linear time proportional to the number of elements in the array, while the sorting process takes logarithmic time proportional to the number of elements in each half. The overall time complexity of merge sort is O(n log n) because the number of elements in each half is reduced by half with each iteration of the sorting process.</li>
</ul>
</li>
<li>Space O(n)
<ul>
<li>Merge sort has a space complexity of O(n) because it uses an auxiliary array of size n to store the sorted elements during the merging step.</li>
<li>merge sort requires an auxiliary array to store the result of each merging step. The size of this array is proportional to the number of elements in the array, which means that the space complexity of merge sort is O(n). Additionally, merge sort requires a small amount of additional memory to store the recursive call stack, but this memory usage is typically not significant compared to the size of the auxiliary array.</li>
</ul>
</li>
</ul>
</li>
<li>Quick Sort
<ul>
<li>Time
<ul>
<li>(avg) O(n log(n))
<ul>
<li>The pivot is then used as a pivot for recursive calls on the two partitioned subarrays. When the pivot is chosen optimally and the array is randomly shuffled, the size of each partition is roughly equal, which results in a good average time complexity of O(n log n)</li>
</ul>
</li>
<li>(worse) O(n^2)
<ul>
<li>if the pivot is always chosen poorly, the time complexity of quick sort can be O(n^2), which makes its time complexity heavily dependent on the choice of pivot.</li>
</ul>
</li>
</ul>
</li>
<li>Space O(log(n))
<ul>
<li>The space complexity of quick sort is O(log n) in the average case, and O(n) in the worst case, where n is the number of elements in the array. This is because quick sort uses a recursive approach, where each recursive call uses a small amount of memory proportional to the size of the call stack. In the average case, when the pivot is chosen optimally and the array is randomly shuffled, the size of each partition is roughly equal, which results in a good average space complexity of O(log n). However, in the worst case, if the pivot is always chosen poorly, the size of one partition can be much larger than the other, which results in a call stack with a height proportional to the number of elements in the array, resulting in a worst-case space complexity of O(n)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>non-comparison</p>
<ul>
<li>Radix sort
<ul>
<li>Time O(nk)</li>
<li>Space O(n+k)</li>
<li>used to sort integrers or strings</li>
</ul>
</li>
<li>Counting sort
<ul>
<li>Time O(n+k)</li>
<li>Space O(k)</li>
</ul>
</li>
</ul>
<h1 id="bubble-sort">Bubble sort</h1>
<h3 id="use-case">Use case</h3>
<ul>
<li>Educational purposes</li>
<li>small arrays</li>
<li>stable sorting
<ul>
<li>For example, consider a list of records that represent people, where each record has a name and an age. If we sort the list based on age, it is important to maintain the relative order of people with the same age, so that the order of their names is preserved in the sorted list. A stable sorting algorithm, such as merge sort, would ensure that the relative order of equal elements is preserved, while an unstable sorting algorithm, such as quick sort, would not.</li>
</ul>
</li>
</ul>
<blockquote>
<p>not recommended for use in practical applications due to its poor time complexity of O(n^2)</p>
</blockquote>
<h3 id="concept">Concept</h3>
<p>Compare two values and move the larger value to the right in each iteration.
This way, the greatest value will end up on the right side in each iteration and will be locked and excluded from subsequent iterations.</p>
<h3 id="how-it-works">How it works</h3>
<p>input</p>
<pre><code>7 5 6 1 3
</code></pre>
<p>i=4, j=0, j&amp;j+1, (<code>5&lt;7</code>, swap)</p>
<pre><code>7 5 6 1 3
5 7 6 1 3
j j
</code></pre>
<p>i=4, j=1, j&amp;j+1,  (<code>7&gt;6</code>, swap)</p>
<pre><code>5 7 6 1 3
5 6 7 1 3
  j j
</code></pre>
<p>i=4, j=2, j&amp;j+1,  (<code>7&gt;1</code>, swap)</p>
<pre><code>5 6 7 1 3
5 6 1 7 3
    j j
</code></pre>
<p>i=4, j=3, j&amp;j+1,  (<code>7&gt;3</code>, swap)</p>
<pre><code>5 6 1 7 3
5 6 1 3 7
      j j
</code></pre>
<p>i=3, j=0, j&amp;j+1,  (<code>5&lt;6</code>, do nothing)</p>
<pre><code>5 6 1 3 7
j j
</code></pre>
<p>i=3, j=1, j&amp;j+1,  (<code>6&gt;1</code>, swap)</p>
<pre><code>5 6 1 3 7
5 1 6 3 7
  j j
</code></pre>
<p>i=3, j=2, j&amp;j+1,  (<code>6&gt;3</code>, swap)</p>
<pre><code>5 1 6 3 7
5 1 3 6 7
    j j
</code></pre>
<p>i=2, j=0, j&amp;j+1,  (<code>5&gt;1</code>, swap)</p>
<pre><code>5 1 3 6 7
1 5 3 6 7
j j
</code></pre>
<p>i=2, j=1, j&amp;j+1,  (<code>5&gt;3</code>, swap)</p>
<pre><code>1 5 3 6 7
1 3 5 6 7
  j j
</code></pre>
<p>i=1, j=0, j&amp;j+1,  (<code>1&lt;3</code>, do nothing)</p>
<pre><code>1 3 5 6 7
j j
</code></pre>
<p>end</p>
<h1 id="insertion-sort">Insertion sort</h1>
<h3 id="use-case-1">Use case</h3>
<ul>
<li>small arrays</li>
<li>partially sorted array</li>
<li>stable sorting</li>
<li>online sorting
<ul>
<li>For example, consider a system that generates log events in real-time and needs to sort the events based on their timestamp. An online sorting algorithm, such as insertion sort, would be a good choice in this scenario, since it can sort the events as they are generated, rather than waiting until all the events have been generated before sorting the entire array.</li>
</ul>
</li>
</ul>
<blockquote>
<p>suitable for small arrays and partially sorted arrays</p>
</blockquote>
<h3 id="concept-1">Concept</h3>
<p>Set a starting point (i) that moves forward in each iteration after comparing all the numbers prior to it and move the smaller number to the left.</p>
<h3 id="how-it-works-1">How it works?</h3>
<p>input</p>
<pre><code>7 8 5 2 4 6 3
</code></pre>
<p>i=1, j=1, j&amp;j-1 (<code>7&lt;8</code>, do nothing)</p>
<pre><code>7 8 5 2 4 6 3
i
j j
</code></pre>
<blockquote>
<p>i is a starting point and j will be reduced by 1 in each i loop to compare 2 values</p>
</blockquote>
<p>i=2, j=2, j&amp;j-1  (<code>8&gt;5</code>, swap)</p>
<pre><code>7 8 5 2 4 6 3
7 5 8 2 4 6 3
  i
  j j
</code></pre>
<p>i=2, j=1, j&amp;j-1  (<code>7&gt;5</code>, swap)</p>
<pre><code>7 5 8 2 4 6 3
5 7 8 2 4 6 3
  i
j j
</code></pre>
<p>i=3, j=3, j&amp;j-1  (<code>8&gt;2</code>, swap)</p>
<pre><code>5 7 8 2 4 6 3
5 7 2 8 4 6 3
    i
    j j
</code></pre>
<p>i=3, j=2, j&amp;j-1  (<code>7&gt;2</code>, swap)</p>
<pre><code>5 7 2 8 4 6 3
5 2 7 8 4 6 3
    i
  j j
</code></pre>
<p>i=3, j=1, j&amp;j-1  (<code>5&gt;2</code>, swap)</p>
<pre><code>5 2 7 8 4 6 3
2 5 7 8 4 6 3
    i
j j
</code></pre>
<p>i=4, j=4, j&amp;j-1  (<code>8&gt;4</code>, swap)</p>
<pre><code>2 5 7 8 4 6 3
2 5 7 4 8 6 3
      i
      j j
</code></pre>
<p>i=4, j=3, j&amp;j-1  (<code>7&gt;4</code>, swap)</p>
<pre><code>2 5 7 4 8 6 3
2 5 4 7 8 6 3
      i
    j j
</code></pre>
<p>i=4, j=2, j&amp;j-1  (<code>5&gt;4</code>, swap)</p>
<pre><code>2 5 4 7 8 6 3
2 4 5 7 8 6 3
      i
  j j
</code></pre>
<p>i=4, j=1, j&amp;j-1  (<code>2&lt;4</code>, do nothing)</p>
<pre><code>2 4 5 7 8 6 3
      i
j j
</code></pre>
<p>i=5, j=5, j&amp;j-1  (<code>8&gt;6</code>, swap)</p>
<pre><code>2 4 5 7 8 6 3
2 4 5 7 6 8 3
        i
        j j
</code></pre>
<p>i=5, j=4, j&amp;j-1  (<code>7&gt;6</code>, swap)</p>
<pre><code>2 4 5 7 6 8 3
2 4 5 6 7 8 3
        i
      j j
</code></pre>
<p>i=5, j=3, j&amp;j-1  (<code>5&lt;6</code>, do nothing)</p>
<pre><code>2 4 5 6 7 8 3
        i
    j j
</code></pre>
<p>i=5, j=2, j&amp;j-1  (<code>4&lt;5</code>, do nothing)</p>
<pre><code>2 4 5 6 7 8 3
        i
  j j
</code></pre>
<p>i=5, j=1, j&amp;j-1  (<code>2&lt;4</code>, do nothing)</p>
<pre><code>2 4 5 6 7 8 3
        i
j j
</code></pre>
<p>i=6, j=6, j&amp;j-1  (<code>8&gt;3</code>, swap)</p>
<pre><code>2 4 5 6 7 8 3
2 4 5 6 7 3 8
          i
          j j
</code></pre>
<p>i=6, j=5, j&amp;j-1  (<code>7&gt;3</code>, swap)</p>
<pre><code>2 4 5 6 7 3 8
2 4 5 6 3 7 8
          i
        j j
</code></pre>
<p>i=6, j=4, j&amp;j-1  (<code>6&gt;3</code>, swap)</p>
<pre><code>2 4 5 6 3 7 8
2 4 5 3 6 7 8
          i
      j j
</code></pre>
<p>i=6, j=3, j&amp;j-1  (<code>5&gt;3</code>, swap)</p>
<pre><code>2 4 5 3 6 7 8
2 4 3 5 6 7 8
          i
    j j
</code></pre>
<p>i=6, j=2, j&amp;j-1  (<code>4&gt;3</code>, swap)</p>
<pre><code>2 4 3 5 6 7 8
2 3 4 5 6 7 8
          i
  j j
</code></pre>
<p>i=6, j=1, j&amp;j-1  (<code>2&gt;3</code>, do nothing)</p>
<pre><code>2 3 4 5 6 7 8
          i
j j
</code></pre>
<p>end</p>
<h1 id="selection-sort">Selection sort</h1>
<h3 id="user-case">User case</h3>
<ul>
<li>Educational purposes</li>
<li>Space-constrained systems</li>
<li>Stable sorting</li>
</ul>
<blockquote>
<p>not commonly used in practice due to its poor performance</p>
</blockquote>
<h3 id="concept-2">Concept</h3>
<p>Set a starting point (i) to find the minimum after it and swap it with the minimum.
Lock the minimum and move the start point forward in each iteration.</p>
<h3 id="how-it-works-2">How it works</h3>
<p>input</p>
<pre><code>2 8 1 3 9
</code></pre>
<p>i=0, minIdx=0, j=0, j+1 (<code>2&lt;8</code>, do nothing)</p>
<pre><code>2 8 1 3 9
i j
m
</code></pre>
<p>i=0, minIdx=0, j=1, j+1 (<code>2&gt;1</code>, to be updated)</p>
<pre><code>2 8 1 3 9
i   j
m
</code></pre>
<p>i=0, minIdx=2, j=1, j+1 (update minIdx)</p>
<pre><code>2 8 1 3 9
i   j
    m
</code></pre>
<p>i=0, midIdx=2, j=2, j+1 (<code>1&lt;3</code>, do nothing)</p>
<pre><code>2 8 1 3 9
i   m j
</code></pre>
<p>i=0, midIdx=2, j=3, j+1 (<code>1&lt;9</code>, do nothing)</p>
<pre><code>2 8 1 3 9
i   m   j
</code></pre>
<p>i=0, midIdx=2, j=3, j+1 (end of iteration, swap min with i)</p>
<pre><code>1 8 2 3 9
m   i   j
</code></pre>
<p>i=1, midIdx=1, j=1, j+1 (<code>8&gt;2</code>, to be updated)</p>
<pre><code>1 8 2 3 9
  m j
  i
</code></pre>
<p>i=1, midIdx=2, j=1, j+1 (update minIdx)</p>
<pre><code>1 8 2 3 9
  i j
    m
</code></pre>
<p>i=1, midIdx=2, j=2, j+1 (<code>2&lt;3</code>, do nothing)</p>
<pre><code>1 8 2 3 9
  i m j
</code></pre>
<p>i=1, midIdx=2, j=3, j+1 (<code>2&lt;9</code>, do nothing)</p>
<pre><code>1 8 2 3 9
  i m   j
</code></pre>
<p>i=1, midIdx=2, j=3, j+1 (end of iteration, swap min with i)</p>
<pre><code>1 2 8 3 9
  m i   j
</code></pre>
<p>i=2, midIdx=2, j=2, j+1 (<code>8&gt;3</code>, to be updated)</p>
<pre><code>1 2 8 3 9
    i j
    m
</code></pre>
<p>i=2, midIdx=3, j=2, j+1 (update midIdx)</p>
<pre><code>1 2 8 3 9
    i j
      m
</code></pre>
<p>i=2, midIdx=3, j=3, j+1 (<code>3&lt;9</code>, do nothing)</p>
<pre><code>1 2 8 3 9
    i m j
</code></pre>
<p>i=2, midIdx=3, j=3, j+1 (end of iteration, swap min with i)</p>
<pre><code>1 2 3 8 9
    m i j
</code></pre>
<p>i=3, midIdx=3, j=3, j+1 (<code>8&lt;9</code>, do nothing)</p>
<pre><code>1 2 3 8 9
      i j
      m
</code></pre>
<p>i=3, midIdx=3, j=3, j+1 (end of iteration, swap min with i)</p>
<pre><code>1 2 3 8 9
      i j
      m
</code></pre>
<p>end</p>
<h1 id="merge-sort">Merge sort</h1>
<h3 id="user-case-1">User case</h3>
<ul>
<li>Large arrays</li>
<li>Stable sorting</li>
<li>External sorting
<ul>
<li>Merge sort is often used for external sorting, where the elements to be sorted are too large to be stored in memory all at once. In this case, the elements are divided into smaller chunks that can be sorted and merged in a two-pass process, where the first pass sorts the chunks and the second pass merges the sorted chunks into the final sorted array.</li>
</ul>
</li>
<li>Parallel processing</li>
</ul>
<blockquote>
<p>widely used in practice due to its efficient time complexity and stability</p>
</blockquote>
<h3 id="concept-3">Concept</h3>
<p>Divide the array into two equal-sized sub-arrays until each sub-array contains only one element. Then, merge each sub-array back into one, in order of value, until complete.</p>
<h3 id="how-it-works-3">How it works</h3>
<p>Steps</p>
<pre><code>                [6 5 3 1 8 7 2 4]
                  /           \
             [6 5 3 1]     [8 7 2 4]
              /    \         /    \
          [6 5]  [3 1]    [8 7]   [2 4]
          / \     / \      / \     / \
        [6] [5] [3] [1]  [8] [7] [2] [4]
           \ /    \ /     \ /     \ /
          [5 6]  [1 3]    [7 8]  [2 4]
              \  /          \   /
           [1 3 5 6]      [2 4 7 8]
                  \          /
               [1 2 3 4 5 6 7 8 ]
</code></pre>
<h1 id="quick-sort">Quick sort</h1>
<h3 id="use-case-2">Use case</h3>
<ul>
<li>large array</li>
<li>random data
<ul>
<li>Quick sort is particularly efficient when the elements in the array are randomly ordered, as this leads to a balanced partitioning of the elements, reducing the time complexity.</li>
</ul>
</li>
<li>In-place sorting
<ul>
<li>Quick sort is an in-place sorting algorithm, meaning that it sorts the elements in place without using additional memory. This makes it a good choice for space-constrained systems where memory is limited.</li>
</ul>
</li>
<li>Parallel processing</li>
</ul>
<blockquote>
<p>widely used in practice</p>
</blockquote>
<h3 id="concept-4">Concept</h3>
<p>Choose a pivot element, partition the data set into two sub-arrays recursively based on the pivot element,
and sort each sub-array by moving values less than the pivot to the left and values greater than the pivot to the right.
When all sub-arrays contain only one element, the entire array is considered sorted.</p>
<h3 id="how-it-works-4">How it works</h3>
<p>The process</p>
<pre><code>j
6 3 7 5 1 2 [4]    6 &gt; 4
i

  j
6 3 7 5 1 2 [4]     3 &lt; 4
i

  j
3 6 7 5 1 2 [4]     swap
i

  j
3 6 7 5 1 2 [4]     i+1
  i

    j
3 6 7 5 1 2 [4]     7 &gt; 4
  i

      j
3 6 7 5 1 2 [4]     5 &gt; 4
  i

        j
3 6 7 5 1 2 [4]     1 &lt; 4
  i

        j
3 1 7 5 6 2 [4]     swap
  i

        j
3 1 7 5 6 2 [4]     i+1
    i

          j
3 1 7 5 6 2 [4]
    i

          j
3 1 7 5 6 2 [4]     2 &lt; 4
    i

          j
3 1 2 5 6 7 [4]     swap
    i

          j
3 1 2 5 6 7 [4]     i+1
      i

             j
3 1 2 5 6 7 [4]     loop ends
      i
</code></pre>
<p>swap pivot and i</p>
<pre><code>3 1 2 [4] 6 7 5
</code></pre>
<p>Now, all elements that are less than the pivot are before it, and all elements that are greater than the pivot are after it.</p>
<p>Then divide the array into two and repeat the sorting process recursively for each part using the same steps</p>
<pre><code>[3 1 2]  4  [6 7 5]
</code></pre>
<p>and go on&hellip;</p>
<h1 id="heap-sort">Heap sort</h1>
<p>TODO</p>
<h1 id="binary-search">binary search</h1>
<ul>
<li>必須是已經排序過的陣列</li>
<li>每一次取中間位置的值, 比對大小再向左向右找</li>
<li>最佳時間複雜度：O(1)</li>
<li>平均時間複雜度：O(log n)</li>
<li>最差時間複雜度：O(log n)</li>
<li>空間複雜度：O(1)</li>
</ul>
<h3 id="depth-first-search-dfs-on-a-binary-tree">Depth First Search (DFS) on a Binary tree</h3>
<p>與 BFS 一樣是用來看這個點有沒有辦法到另一個點或是否某個點有存在在 graph 裡 (如果所有點都有連接)</p>
<ul>
<li>root node <code>&gt;</code> 左節點; root node <code>&lt;</code> 右節點</li>
<li>原理是先往左再往右找, 從深找到淺</li>
<li>深到沒有子 node 再&quot;回頭&quot;換右邊</li>
<li>如果最後回到 root node (最上層) 就代表要找的 node 沒有存在</li>
</ul>
<h1 id="interview">Interview</h1>
<h3 id="top-6-coding-interview-concepts">Top 6 Coding Interview Concepts</h3>
<ul>
<li>Heaps
<ul>
<li>min-heaps</li>
<li>max-heaps</li>
<li>K closest points to origin</li>
<li>network delay time</li>
<li>min cost to connect all points</li>
</ul>
</li>
<li>sliding window
<ul>
<li>Best time to buy/sell a stock</li>
</ul>
</li>
<li>Binary search
<ul>
<li>Guess number higher or lower</li>
<li>search a 2-D matrix</li>
<li>binary search</li>
</ul>
</li>
<li>DFS &amp; BFS
<ul>
<li>usually O(V+E), time &amp; space complexity</li>
<li>number of islands</li>
</ul>
</li>
<li>Recursion
<ul>
<li>includes Trees, Graphs, Backtracking, DP</li>
<li>N-queens</li>
</ul>
</li>
<li>Hash maps
<ul>
<li>Two sum</li>
</ul>
</li>
</ul>
<h3 id="the-10-most-important-concepts-for-coding-interviews">The 10 Most Important Concepts For Coding Interviews</h3>
<ul>
<li>logarithum</li>
<li>DFS/BFS</li>
<li>binary search</li>
<li>sliding window</li>
<li>recursion</li>
<li>inverting a binary tree and reverting a linked list</li>
<li>suffix trees</li>
<li>heaps</li>
<li>dynamic programming</li>
<li>sorting algorithum</li>
</ul>
<h4 id="ref">ref</h4>
<ul>
<li><a href="https://www.interviewcake.com/article/java/big-o-notation-time-and-space-complexity">Big O Notation</a></li>
<li><a href="https://goo.gl/mKYH19">初學者學演算法｜從時間複雜度認識常見演算法（一）</a></li>
</ul>

</article>



</html>
