<!DOCTYPE html>
<html lang="en-us">
<title>Algorithms | Software</title>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.104.2" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="/css/index.css">
<link rel="canonical" href="/posts/algorithms/">
<link rel="alternate" type="application/rss+xml" href="" title="Software">

<header>
  
    <a href="/" class="title">Software</a>
  
  
</header>

<article>
  <header>
    <h1>Algorithms</h1>
    <time datetime="2017-05-20T18:56:16&#43;08:00">May 20, 2017</time>
  </header>
  <h1 id="sorting-algorithm">Sorting algorithm</h1>
<p>Comparison</p>
<ul>
<li>Bubble Sort
<ul>
<li>Time O(n^2)
<ul>
<li>bubble sort works by repeatedly swapping adjacent elements if they are in the wrong order, and it continues this process until the array is sorted. The number of swaps required to sort the array is proportional to the square of the number of elements in the array</li>
</ul>
</li>
<li>Space O(1)</li>
</ul>
</li>
<li>Insertion Sort
<ul>
<li>Time O(n^2)
<ul>
<li>insertion sort works by iterating over the elements in the array, and for each element, it shifts all the elements that are greater than it to the right in order to make room for it in its final position. The number of shifts required to insert each element is proportional to the number of elements that have already been processed</li>
</ul>
</li>
<li>Space O(1)</li>
</ul>
</li>
<li>Selection Sort
<ul>
<li>Time O(n^2)
<ul>
<li>selection sort works by repeatedly finding the minimum element in the unsorted portion of the array and swapping it with the first unsorted element. The number of swaps required to sort the array is proportional to the square of the number of elements in the array</li>
</ul>
</li>
<li>Space O(1)</li>
</ul>
</li>
<li>Merge Sort
<ul>
<li>Time O(n log(n))
<ul>
<li>merge sort works by dividing the array into two halves, sorting each half separately, and then merging the two sorted halves back together. The merging process takes linear time proportional to the number of elements in the array, while the sorting process takes logarithmic time proportional to the number of elements in each half. The overall time complexity of merge sort is O(n log n) because the number of elements in each half is reduced by half with each iteration of the sorting process.</li>
</ul>
</li>
<li>Space O(n)
<ul>
<li>Merge sort has a space complexity of O(n) because it uses an auxiliary array of size n to store the sorted elements during the merging step.</li>
<li>merge sort requires an auxiliary array to store the result of each merging step. The size of this array is proportional to the number of elements in the array, which means that the space complexity of merge sort is O(n). Additionally, merge sort requires a small amount of additional memory to store the recursive call stack, but this memory usage is typically not significant compared to the size of the auxiliary array.</li>
</ul>
</li>
</ul>
</li>
<li>Quick Sort
<ul>
<li>Time
<ul>
<li>(avg) O(n log(n))
<ul>
<li>The pivot is then used as a pivot for recursive calls on the two partitioned subarrays. When the pivot is chosen optimally and the array is randomly shuffled, the size of each partition is roughly equal, which results in a good average time complexity of O(n log n)</li>
</ul>
</li>
<li>(worse) O(n^2)
<ul>
<li>if the pivot is always chosen poorly, the time complexity of quick sort can be O(n^2), which makes its time complexity heavily dependent on the choice of pivot.</li>
</ul>
</li>
</ul>
</li>
<li>Space O(log(n))
<ul>
<li>The space complexity of quick sort is O(log n) in the average case, and O(n) in the worst case, where n is the number of elements in the array. This is because quick sort uses a recursive approach, where each recursive call uses a small amount of memory proportional to the size of the call stack. In the average case, when the pivot is chosen optimally and the array is randomly shuffled, the size of each partition is roughly equal, which results in a good average space complexity of O(log n). However, in the worst case, if the pivot is always chosen poorly, the size of one partition can be much larger than the other, which results in a call stack with a height proportional to the number of elements in the array, resulting in a worst-case space complexity of O(n)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>non-comparison</p>
<ul>
<li>Radix sort
<ul>
<li>Time O(nk)</li>
<li>Space O(n+k)</li>
<li>used to sort integrers or strings</li>
</ul>
</li>
<li>Counting sort
<ul>
<li>Time O(n+k)</li>
<li>Space O(k)</li>
</ul>
</li>
</ul>
<h1 id="bubble-sort">Bubble sort</h1>
<h3 id="use-case">Use case</h3>
<ul>
<li>Educational purposes</li>
<li>small arrays</li>
<li>stable sorting
<ul>
<li>For example, consider a list of records that represent people, where each record has a name and an age. If we sort the list based on age, it is important to maintain the relative order of people with the same age, so that the order of their names is preserved in the sorted list. A stable sorting algorithm, such as merge sort, would ensure that the relative order of equal elements is preserved, while an unstable sorting algorithm, such as quick sort, would not.</li>
</ul>
</li>
</ul>
<blockquote>
<p>not recommended for use in practical applications due to its poor time complexity of O(n^2)</p>
</blockquote>
<h3 id="concept">Concept</h3>
<p>Compare two values and move the larger value to the right in each iteration.
This way, the greatest value will end up on the right side in each iteration and will be locked and excluded from subsequent iterations.</p>
<h3 id="how-it-works">How it works</h3>
<p>input</p>
<pre><code>7 5 6 1 3
</code></pre>
<p>i=4, j=0, j&amp;j+1, (<code>5&lt;7</code>, swap)</p>
<pre><code>7 5 6 1 3
5 7 6 1 3
j j
</code></pre>
<p>i=4, j=1, j&amp;j+1,  (<code>7&gt;6</code>, swap)</p>
<pre><code>5 7 6 1 3
5 6 7 1 3
  j j
</code></pre>
<p>i=4, j=2, j&amp;j+1,  (<code>7&gt;1</code>, swap)</p>
<pre><code>5 6 7 1 3
5 6 1 7 3
    j j
</code></pre>
<p>i=4, j=3, j&amp;j+1,  (<code>7&gt;3</code>, swap)</p>
<pre><code>5 6 1 7 3
5 6 1 3 7
      j j
</code></pre>
<p>i=3, j=0, j&amp;j+1,  (<code>5&lt;6</code>, do nothing)</p>
<pre><code>5 6 1 3 7
j j
</code></pre>
<p>i=3, j=1, j&amp;j+1,  (<code>6&gt;1</code>, swap)</p>
<pre><code>5 6 1 3 7
5 1 6 3 7
  j j
</code></pre>
<p>i=3, j=2, j&amp;j+1,  (<code>6&gt;3</code>, swap)</p>
<pre><code>5 1 6 3 7
5 1 3 6 7
    j j
</code></pre>
<p>i=2, j=0, j&amp;j+1,  (<code>5&gt;1</code>, swap)</p>
<pre><code>5 1 3 6 7
1 5 3 6 7
j j
</code></pre>
<p>i=2, j=1, j&amp;j+1,  (<code>5&gt;3</code>, swap)</p>
<pre><code>1 5 3 6 7
1 3 5 6 7
  j j
</code></pre>
<p>i=1, j=0, j&amp;j+1,  (<code>1&lt;3</code>, do nothing)</p>
<pre><code>1 3 5 6 7
j j
</code></pre>
<p>end</p>
<h1 id="insertion-sort">Insertion sort</h1>
<h3 id="use-case-1">Use case</h3>
<ul>
<li>small arrays</li>
<li>partially sorted array</li>
<li>stable sorting</li>
<li>online sorting
<ul>
<li>For example, consider a system that generates log events in real-time and needs to sort the events based on their timestamp. An online sorting algorithm, such as insertion sort, would be a good choice in this scenario, since it can sort the events as they are generated, rather than waiting until all the events have been generated before sorting the entire array.</li>
</ul>
</li>
</ul>
<blockquote>
<p>suitable for small arrays and partially sorted arrays</p>
</blockquote>
<h3 id="concept-1">Concept</h3>
<p>Set a starting point (i) that moves forward in each iteration after comparing all the numbers prior to it and move the smaller number to the left.</p>
<h3 id="how-it-works-1">How it works?</h3>
<p>input</p>
<pre><code>7 8 5 2 4 6 3
</code></pre>
<p>i=1, j=1, j&amp;j-1 (<code>7&lt;8</code>, do nothing)</p>
<pre><code>7 8 5 2 4 6 3
i
j j
</code></pre>
<blockquote>
<p>i is a starting point and j will be reduced by 1 in each i loop to compare 2 values</p>
</blockquote>
<p>i=2, j=2, j&amp;j-1  (<code>8&gt;5</code>, swap)</p>
<pre><code>7 8 5 2 4 6 3
7 5 8 2 4 6 3
  i
  j j
</code></pre>
<p>i=2, j=1, j&amp;j-1  (<code>7&gt;5</code>, swap)</p>
<pre><code>7 5 8 2 4 6 3
5 7 8 2 4 6 3
  i
j j
</code></pre>
<p>i=3, j=3, j&amp;j-1  (<code>8&gt;2</code>, swap)</p>
<pre><code>5 7 8 2 4 6 3
5 7 2 8 4 6 3
    i
    j j
</code></pre>
<p>i=3, j=2, j&amp;j-1  (<code>7&gt;2</code>, swap)</p>
<pre><code>5 7 2 8 4 6 3
5 2 7 8 4 6 3
    i
  j j
</code></pre>
<p>i=3, j=1, j&amp;j-1  (<code>5&gt;2</code>, swap)</p>
<pre><code>5 2 7 8 4 6 3
2 5 7 8 4 6 3
    i
j j
</code></pre>
<p>i=4, j=4, j&amp;j-1  (<code>8&gt;4</code>, swap)</p>
<pre><code>2 5 7 8 4 6 3
2 5 7 4 8 6 3
      i
      j j
</code></pre>
<p>i=4, j=3, j&amp;j-1  (<code>7&gt;4</code>, swap)</p>
<pre><code>2 5 7 4 8 6 3
2 5 4 7 8 6 3
      i
    j j
</code></pre>
<p>i=4, j=2, j&amp;j-1  (<code>5&gt;4</code>, swap)</p>
<pre><code>2 5 4 7 8 6 3
2 4 5 7 8 6 3
      i
  j j
</code></pre>
<p>i=4, j=1, j&amp;j-1  (<code>2&lt;4</code>, do nothing)</p>
<pre><code>2 4 5 7 8 6 3
      i
j j
</code></pre>
<p>i=5, j=5, j&amp;j-1  (<code>8&gt;6</code>, swap)</p>
<pre><code>2 4 5 7 8 6 3
2 4 5 7 6 8 3
        i
        j j
</code></pre>
<p>i=5, j=4, j&amp;j-1  (<code>7&gt;6</code>, swap)</p>
<pre><code>2 4 5 7 6 8 3
2 4 5 6 7 8 3
        i
      j j
</code></pre>
<p>i=5, j=3, j&amp;j-1  (<code>5&lt;6</code>, do nothing)</p>
<pre><code>2 4 5 6 7 8 3
        i
    j j
</code></pre>
<p>i=5, j=2, j&amp;j-1  (<code>4&lt;5</code>, do nothing)</p>
<pre><code>2 4 5 6 7 8 3
        i
  j j
</code></pre>
<p>i=5, j=1, j&amp;j-1  (<code>2&lt;4</code>, do nothing)</p>
<pre><code>2 4 5 6 7 8 3
        i
j j
</code></pre>
<p>i=6, j=6, j&amp;j-1  (<code>8&gt;3</code>, swap)</p>
<pre><code>2 4 5 6 7 8 3
2 4 5 6 7 3 8
          i
          j j
</code></pre>
<p>i=6, j=5, j&amp;j-1  (<code>7&gt;3</code>, swap)</p>
<pre><code>2 4 5 6 7 3 8
2 4 5 6 3 7 8
          i
        j j
</code></pre>
<p>i=6, j=4, j&amp;j-1  (<code>6&gt;3</code>, swap)</p>
<pre><code>2 4 5 6 3 7 8
2 4 5 3 6 7 8
          i
      j j
</code></pre>
<p>i=6, j=3, j&amp;j-1  (<code>5&gt;3</code>, swap)</p>
<pre><code>2 4 5 3 6 7 8
2 4 3 5 6 7 8
          i
    j j
</code></pre>
<p>i=6, j=2, j&amp;j-1  (<code>4&gt;3</code>, swap)</p>
<pre><code>2 4 3 5 6 7 8
2 3 4 5 6 7 8
          i
  j j
</code></pre>
<p>i=6, j=1, j&amp;j-1  (<code>2&gt;3</code>, do nothing)</p>
<pre><code>2 3 4 5 6 7 8
          i
j j
</code></pre>
<p>end</p>
<h1 id="selection-sort">Selection sort</h1>
<h3 id="user-case">User case</h3>
<ul>
<li>Educational purposes</li>
<li>Space-constrained systems</li>
<li>Stable sorting</li>
</ul>
<blockquote>
<p>not commonly used in practice due to its poor performance</p>
</blockquote>
<h3 id="concept-2">Concept</h3>
<p>Set a starting point (i) to find the minimum after it and swap it with the minimum.
Lock the minimum and move the start point forward in each iteration.</p>
<h3 id="how-it-works-2">How it works</h3>
<p>input</p>
<pre><code>2 8 1 3 9
</code></pre>
<p>i=0, minIdx=0, j=0, j+1 (<code>2&lt;8</code>, do nothing)</p>
<pre><code>2 8 1 3 9
i j
m
</code></pre>
<p>i=0, minIdx=0, j=1, j+1 (<code>2&gt;1</code>, to be updated)</p>
<pre><code>2 8 1 3 9
i   j
m
</code></pre>
<p>i=0, minIdx=2, j=1, j+1 (update minIdx)</p>
<pre><code>2 8 1 3 9
i   j
    m
</code></pre>
<p>i=0, midIdx=2, j=2, j+1 (<code>1&lt;3</code>, do nothing)</p>
<pre><code>2 8 1 3 9
i   m j
</code></pre>
<p>i=0, midIdx=2, j=3, j+1 (<code>1&lt;9</code>, do nothing)</p>
<pre><code>2 8 1 3 9
i   m   j
</code></pre>
<p>i=0, midIdx=2, j=3, j+1 (end of iteration, swap min with i)</p>
<pre><code>1 8 2 3 9
m   i   j
</code></pre>
<p>i=1, midIdx=1, j=1, j+1 (<code>8&gt;2</code>, to be updated)</p>
<pre><code>1 8 2 3 9
  m j
  i
</code></pre>
<p>i=1, midIdx=2, j=1, j+1 (update minIdx)</p>
<pre><code>1 8 2 3 9
  i j
    m
</code></pre>
<p>i=1, midIdx=2, j=2, j+1 (<code>2&lt;3</code>, do nothing)</p>
<pre><code>1 8 2 3 9
  i m j
</code></pre>
<p>i=1, midIdx=2, j=3, j+1 (<code>2&lt;9</code>, do nothing)</p>
<pre><code>1 8 2 3 9
  i m   j
</code></pre>
<p>i=1, midIdx=2, j=3, j+1 (end of iteration, swap min with i)</p>
<pre><code>1 2 8 3 9
  m i   j
</code></pre>
<p>i=2, midIdx=2, j=2, j+1 (<code>8&gt;3</code>, to be updated)</p>
<pre><code>1 2 8 3 9
    i j
    m
</code></pre>
<p>i=2, midIdx=3, j=2, j+1 (update midIdx)</p>
<pre><code>1 2 8 3 9
    i j
      m
</code></pre>
<p>i=2, midIdx=3, j=3, j+1 (<code>3&lt;9</code>, do nothing)</p>
<pre><code>1 2 8 3 9
    i m j
</code></pre>
<p>i=2, midIdx=3, j=3, j+1 (end of iteration, swap min with i)</p>
<pre><code>1 2 3 8 9
    m i j
</code></pre>
<p>i=3, midIdx=3, j=3, j+1 (<code>8&lt;9</code>, do nothing)</p>
<pre><code>1 2 3 8 9
      i j
      m
</code></pre>
<p>i=3, midIdx=3, j=3, j+1 (end of iteration, swap min with i)</p>
<pre><code>1 2 3 8 9
      i j
      m
</code></pre>
<p>end</p>
<h1 id="merge-sort">Merge sort</h1>
<h3 id="user-case-1">User case</h3>
<ul>
<li>Large arrays</li>
<li>Stable sorting</li>
<li>External sorting
<ul>
<li>Merge sort is often used for external sorting, where the elements to be sorted are too large to be stored in memory all at once. In this case, the elements are divided into smaller chunks that can be sorted and merged in a two-pass process, where the first pass sorts the chunks and the second pass merges the sorted chunks into the final sorted array.</li>
</ul>
</li>
<li>Parallel processing</li>
</ul>
<blockquote>
<p>widely used in practice due to its efficient time complexity and stability</p>
</blockquote>
<h3 id="concept-3">Concept</h3>
<p>Divide the array into two equal-sized sub-arrays until each sub-array contains only one element. Then, merge each sub-array back into one, in order of value, until complete.</p>
<h3 id="how-it-works-3">How it works</h3>
<p>Steps</p>
<pre><code>                [6 5 3 1 8 7 2 4]
                  /           \
             [6 5 3 1]     [8 7 2 4]
              /    \         /    \
          [6 5]  [3 1]    [8 7]   [2 4]
          / \     / \      / \     / \
        [6] [5] [3] [1]  [8] [7] [2] [4]
           \ /    \ /     \ /     \ /
          [5 6]  [1 3]    [7 8]  [2 4]
              \  /          \   /
           [1 3 5 6]      [2 4 7 8]
                  \          /
               [1 2 3 4 5 6 7 8 ]
</code></pre>
<h1 id="quick-sort">Quick sort</h1>
<h3 id="use-case-2">Use case</h3>
<ul>
<li>large array</li>
<li>random data
<ul>
<li>Quick sort is particularly efficient when the elements in the array are randomly ordered, as this leads to a balanced partitioning of the elements, reducing the time complexity.</li>
</ul>
</li>
<li>In-place sorting
<ul>
<li>Quick sort is an in-place sorting algorithm, meaning that it sorts the elements in place without using additional memory. This makes it a good choice for space-constrained systems where memory is limited.</li>
</ul>
</li>
<li>Parallel processing</li>
</ul>
<blockquote>
<p>widely used in practice</p>
</blockquote>
<h3 id="concept-4">Concept</h3>
<p>Choose a pivot element, partition the data set into two sub-arrays recursively based on the pivot element,
and sort each sub-array by moving values less than the pivot to the left and values greater than the pivot to the right.
When all sub-arrays contain only one element, the entire array is considered sorted.</p>
<h3 id="how-it-works-4">How it works</h3>
<p>The process</p>
<pre><code>j
6 3 7 5 1 2 [4]    6 &gt; 4
i

  j
6 3 7 5 1 2 [4]     3 &lt; 4
i

  j
3 6 7 5 1 2 [4]     swap
i

  j
3 6 7 5 1 2 [4]     i+1
  i

    j
3 6 7 5 1 2 [4]     7 &gt; 4
  i

      j
3 6 7 5 1 2 [4]     5 &gt; 4
  i

        j
3 6 7 5 1 2 [4]     1 &lt; 4
  i

        j
3 1 7 5 6 2 [4]     swap
  i

        j
3 1 7 5 6 2 [4]     i+1
    i

          j
3 1 7 5 6 2 [4]
    i

          j
3 1 7 5 6 2 [4]     2 &lt; 4
    i

          j
3 1 2 5 6 7 [4]     swap
    i

          j
3 1 2 5 6 7 [4]     i+1
      i

             j
3 1 2 5 6 7 [4]     loop ends
      i
</code></pre>
<p>swap pivot and i</p>
<pre><code>3 1 2 [4] 6 7 5
</code></pre>
<p>Now, all elements that are less than the pivot are before it, and all elements that are greater than the pivot are after it.</p>
<p>Then divide the array into two and repeat the sorting process recursively for each part using the same steps</p>
<pre><code>[3 1 2]  4  [6 7 5]
</code></pre>
<p>and go on&hellip;</p>
<h1 id="heap-sort">Heap sort</h1>
<p>TODO</p>
<h1 id="binary-search">binary search</h1>
<h3 id="remove-a-node-in-bst">Remove a node in BST</h3>
<p><code>insert</code> and <code>lookup</code> a node is quite easy, but removing a node is complex.</p>
<p>3 cases</p>
<ul>
<li>no child: just delete</li>
<li>1 child: replace the targetted node with its child node</li>
<li>2 children: there are 2 options to do that (so that the tree can continue to follow the rules of BST).
<ul>
<li>find the minimum value in right subtree, assign it to the node we want to delete (most common)</li>
<li>find the maximum value in left subtree, assign it to the node we want to delete</li>
</ul>
</li>
</ul>
<p>no child</p>
<pre><code>         100                                100
        /    \                             /
      75     125 &lt;- remove      =&gt;       75
</code></pre>
<p>1 child</p>
<pre><code>                100                         100
                /                           /
    remove -&gt; 75              =&gt;          65
             /                            /\
           65                           60  70
           /\
         60  70
</code></pre>
<p>1 child</p>
<pre><code>                3                         3
               / \                       / \
    remove -&gt; 1   4           =&gt;        2   4
               \
                2
</code></pre>
<p>1 child</p>
<pre><code>       3                             3
      / \                           / \
     1   5 &lt;- remove     =&gt;        1   4
        /
       4
</code></pre>
<p>2 children (leftmost in right subtree is 70)</p>
<pre><code>                    75                      75
                   /  \                    /  \
       remove -&gt; 65    85       =&gt;       70    85
                 /\                     /
               60  70                  60
</code></pre>
<p>2 children (leftmost in right subtree is 115)</p>
<pre><code>           100 &lt;- remove                     115
          /   \                             /  \
        75     125               =&gt;       75    125
              /   \                               \
            115    150                            150
</code></pre>
<p>2 children (leftmost in right subtree is 80)</p>
<pre><code>                     100                            100
                     /  \                          /   \
         remove -&gt; 75    125                     80     125
                 /    \          =&gt;            /    \
               65      85                    65      85
              /  \    /  \                  /  \       \
            60   70  80  95               60   70       95
</code></pre>
<p>2 children (leftmost in right subtree is 135)</p>
<pre><code>            100                             100
           /   \                           /   \
         75     125 &lt;- remove            75     135
               /   \             =&gt;            /   \
            115     150                      115   150
                   /   \                             \
                 135   175                           175
</code></pre>
<p>2 children (leftmost in right subtree is 34)</p>
<pre><code>            2                                   2
          /   \                               /   \
         0     33 &lt;- remove                 0      34
              /  \                                /  \
            25    40                            25    40
                 /  \           =&gt;                   /  \
               34    45                            36    45
                 \                                /  \
                  36                            35    39
                  /\
                35  39
</code></pre>
<h1 id="traversal">Traversal</h1>
<h3 id="bfs-breadth-first-search">BFS (Breadth First Search)</h3>
<p>tree</p>
<pre><code>            9
          /   \
        4      20
       / \    /  \
      1   6  15   170
</code></pre>
<p>traversal</p>
<pre><code>9 4 20 1 6 15 170
</code></pre>
<p>pros</p>
<ul>
<li>If Solution exists BFS will definitely find it</li>
<li>easy to find the shortest path between two nodes because BFS visits nodes level-by-level, and it will find the destination node as soon as it is encountered</li>
<li>Never get trapped in unwanted nodes without the solution</li>
<li>useful for finding the maximum or minimum value in a BST</li>
</ul>
<p>cons</p>
<ul>
<li>BFS uses more memory than DFS because it needs to keep track of all nodes at the same level before moving on to deeper levels (e.g. queue)</li>
<li>Slower for deep trees (a higher time complexity than DFS because it visits all nodes at the same level before moving on to the next level)</li>
</ul>
<p>use cases</p>
<ul>
<li>find BT nods</li>
<li>search engine use BFS to build index</li>
<li>GPS navigation</li>
<li>Network problems: BFS can be used to find the shortest path in a network. For example, it can be used to find the shortest path between two nodes in a computer network, or to find the shortest path between two nodes in a social network.</li>
<li>Map problems: BFS can be used to find the shortest path in a map.</li>
<li>recommendation engine
<ul>
<li>on Amazon: what types of items are related or the closet relation to the last book I bought</li>
<li>on FB: what types of friend requests I should be recommended</li>
</ul>
</li>
</ul>
<h3 id="dfs-depth-first-search">DFS (Depth First Search)</h3>
<p>tree</p>
<pre><code>            9
          /   \
        4      20
       / \    /  \
      1   6  15   170
</code></pre>
<p>traversal</p>
<pre><code>9 4 1 6 20 15 170
</code></pre>
<p>pros</p>
<ul>
<li>Memory efficiency: DFS uses a stack to store nodes to be processed, which only requires a limited amount of memory compared to BFS, which uses a queue and requires more memory.</li>
<li>Faster for deep trees because it can quickly reach the bottom-most level of a tree.</li>
<li>Faster in finding a solution: DFS can backtrack and quickly eliminate branches that do not contain a solution especially if the solution is located deep in the graph. For example, consider a problem where you need to find a specific node in a large graph. With DFS, you can start from a node and follow its edges to explore deeper into the graph. If you find the solution, you can stop the search and return the result.</li>
</ul>
<p>cons</p>
<ul>
<li>Can get stuck in an infinite loop: If there are cycles in the graph, DFS may get stuck in an infinite loop, whereas BFS is able to avoid this issue.</li>
<li>Cannot guarantee to find a solution. For example, if we search for Starbucks from my location, it will definitely find one soon. but if we search for a museum, then it will take more time and might not guarantee to find one.</li>
<li>Cannot find the minimal solution if two solutions are available</li>
<li>Slower for shallow trees</li>
</ul>
<p>use cases</p>
<ul>
<li>If we perform DFS on unweighted graph, then it will create minimum spanning tree for all pair shortest path tree</li>
<li>Using DFS we can find path between two given vertices u and v.</li>
<li>topological sorting: Topological sorting is a linear ordering of the vertices in a directed acyclic graph (DAG) (e.g. A-&gt;B-&gt;C-&gt;D)
<ul>
<li>scheduling problems: can be used to schedule jobs from given dependencies among jobs</li>
</ul>
</li>
<li>cycle detection in graphs</li>
<li>solving puzzles with only one solution, such as a maze or a sudoku puzzle.</li>
<li>analysing networks e.g. testing if a graph is bipartite (a graph where vertices can be partitioned into two disjoint sets, with no edges connecting vertices in the same set. It&rsquo;s used in matching, scheduling, and network flow problems and can be easily tested for by coloring vertices with two colors and checking if no two adjacent vertices have the same color.)</li>
<li>on linkedin: If I have a connection someone, I can use DFS for what degree of connection with that person.</li>
</ul>
<h3 id="inorder-vs-preorder-vs-postorder">inorder vs preorder vs postorder</h3>
<p>tree</p>
<pre><code>            9
          /   \
        4      20
       / \    /  \
      1   6  15   170
</code></pre>
<p>inorder</p>
<pre><code>1 4 6 9 15 20 170
</code></pre>
<p>preorder</p>
<pre><code>9 4 1 6 20 15 170
</code></pre>
<p>postorder</p>
<pre><code>1 6 4 15 170 20 9
</code></pre>
<p>use cases:</p>
<ul>
<li>If you know you need to explore the roots before inspecting any leaves, you pick pre-order because you will encounter all the roots before all of the leaves.</li>
<li>If you know you need to explore all the leaves before any nodes, you select post-order because you don&rsquo;t waste any time inspecting roots in search for leaves.</li>
<li>If you know that the tree has an inherent sequence in the nodes, and you want to flatten the tree back into its original sequence, than an in-order traversal should be used.</li>
</ul>
<h3 id="why-does-bfs-not-have-inorder-preorder-and-postorder-implementations-while-dfs-does">Why does BFS not have inorder, preorder, and postorder implementations, while DFS does?</h3>
<ul>
<li>BFS visits nodes in a level-by-level manner, which makes it difficult to visit the nodes in a specific order.</li>
<li>DFS has inorder, preorder, and postorder implementations because it can be used to traverse the tree and visit the nodes in a specific order by visiting the children of a node before visiting the node itself.</li>
</ul>
<h1 id="whats-the-pros-and-cons-of-recursive-solution">What&rsquo;s the pros and cons of recursive solution?</h1>
<p>pros</p>
<ul>
<li>reduce time complexity (if use recursion with memorisation)</li>
<li>cleaner code</li>
<li>Recursion is better at tree traversal
<ul>
<li>One of the more efficient ways to traverse these trees when looking for a specific leaf (or node) is by recursively following a single branch until the end of that branch until you find the value you are looking for.</li>
</ul>
</li>
</ul>
<p>cons</p>
<ul>
<li>use more memory (might cause stack overflow)
<ul>
<li>Because the function has to add to the stack with each recursive call and keep the values there until the call is finished</li>
</ul>
</li>
<li>can be slow (generally, compare to iteration)
<ul>
<li>it requires the allocation of a new stack frame</li>
<li>fibonacci question is a good example. Iteration is much faster than recursion, because iteration saves the value of each calculation for further use.</li>
</ul>
</li>
<li>more difficult to understand and debug</li>
</ul>
<h1 id="other-algorithms">Other algorithms</h1>
<h3 id="shortest-path-of-a-weighted-graph">shortest path (of a weighted graph)</h3>
<ul>
<li>Bellman-Ford
<ul>
<li>support negative weight</li>
</ul>
</li>
<li>Dijkstra</li>
</ul>
<h1 id="dynamic-programming">Dynamic Programming</h1>
<ul>
<li>= Divide &amp; Conquer + Memoisation</li>
</ul>
<h1 id="functional-programming">Functional Programming</h1>
<h1 id="interview">Interview</h1>
<h3 id="top-6-coding-interview-concepts">Top 6 Coding Interview Concepts</h3>
<ul>
<li>Heaps
<ul>
<li>min-heaps</li>
<li>max-heaps</li>
<li>K closest points to origin</li>
<li>network delay time</li>
<li>min cost to connect all points</li>
</ul>
</li>
<li>sliding window
<ul>
<li>Best time to buy/sell a stock</li>
</ul>
</li>
<li>Binary search
<ul>
<li>Guess number higher or lower</li>
<li>search a 2-D matrix</li>
<li>binary search</li>
</ul>
</li>
<li>DFS &amp; BFS
<ul>
<li>usually O(V+E), time &amp; space complexity</li>
<li>number of islands</li>
</ul>
</li>
<li>Recursion
<ul>
<li>includes Trees, Graphs, Backtracking, DP</li>
<li>N-queens</li>
</ul>
</li>
<li>Hash maps
<ul>
<li>Two sum</li>
</ul>
</li>
</ul>
<h3 id="the-10-most-important-concepts-for-coding-interviews">The 10 Most Important Concepts For Coding Interviews</h3>
<ul>
<li>logarithum</li>
<li>DFS/BFS</li>
<li>binary search</li>
<li>sliding window</li>
<li>recursion</li>
<li>inverting a binary tree and reverting a linked list</li>
<li>suffix trees</li>
<li>heaps</li>
<li>dynamic programming</li>
<li>sorting algorithum</li>
</ul>
<h4 id="ref">ref</h4>
<ul>
<li><a href="https://www.interviewcake.com/article/java/big-o-notation-time-and-space-complexity">Big O Notation</a></li>
<li><a href="https://goo.gl/mKYH19">初學者學演算法｜從時間複雜度認識常見演算法（一）</a></li>
<li><a href="https://www.quora.com/What-are-the-advantages-of-using-BFS-over-DFS-or-using-DFS-over-BFS-What-are-the-applications-and-downsides-of-each">bfs vs dfs</a></li>
<li><a href="https://www.tutorialspoint.com/applications-of-dfs-and-bfs-in-data-structures">use cases of BFS/DFS</a></li>
<li><a href="https://medium.com/@williambdale/recursion-the-pros-and-cons-76d32d75973a">recursive</a></li>
<li><a href="https://stackoverflow.com/questions/9456937/when-to-use-preorder-postorder-and-inorder-binary-search-tree-traversal-strate">preorder vs inorder vs postorder</a></li>
</ul>

</article>



</html>
